

---

# ğŸ¤– agents_simulation â€” é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ MVPï¼ˆMCPé€£æºå¯¾å¿œï¼‰

---

## ğŸ§© æ¦‚è¦

ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã¯ **Strands Agents v1.14.0** ã‚’åˆ©ç”¨ã—ã€
ã€Œå¿œå‹Ÿè€… / äººäº‹ / éƒ¨é–€è²¬ä»»è€…ã€ã® 3 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ **é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³** ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

å¾“æ¥ã®ãƒ­ãƒ¼ã‚«ãƒ«å›ºå®šãƒ†ã‚­ã‚¹ãƒˆå®Ÿè£…ã‚’è¶…ãˆã€
**FastMCPï¼ˆv2.13ç³»ï¼‰ã§æä¾›ã•ã‚Œã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã‚µãƒ¼ãƒãƒ¼ç¾¤**
ï¼ˆ`mcp_knowledge/` é…ä¸‹ï¼‰ã¨ **éåŒæœŸã«é€£æº** ã™ã‚‹æ§‹æˆã«é€²åŒ–ã—ã¾ã—ãŸã€‚

---

## ğŸ— ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```bash
agents_simulation/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ applicant_agent.py      # å¿œå‹Ÿè€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆresume / applicant_profile å‚ç…§ï¼‰
â”‚   â”œâ”€â”€ hr_agent.py             # äººäº‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆhr_questions / company_mission å‚ç…§ï¼‰
â”‚   â”œâ”€â”€ dept_agent.py           # é–‹ç™ºéƒ¨é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆdept_questions / company_mission å‚ç…§ï¼‰
â”‚   â”œâ”€â”€ mcp_tool_client.py      # âœ… MCPãƒ„ãƒ¼ãƒ«å…±é€šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆéåŒæœŸå¯¾å¿œï¼‰
â”‚   â””â”€â”€ util.py                 # Strands AgentResult ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚
â”œâ”€â”€ main_sync.py                # å›ºå®šãƒ•ãƒ­ãƒ¼é¢æ¥ï¼ˆHRâ†’Applicantâ†’Deptï¼‰
â”œâ”€â”€ main_autonomous.py          # è‡ªå¾‹ãƒ•ãƒ­ãƒ¼ï¼ˆHRãƒ•ã‚§ãƒ¼ã‚ºâ†’Deptãƒ•ã‚§ãƒ¼ã‚ºï¼‰
â”œâ”€â”€ main_mixed_random.py        # âœ… ãƒ©ãƒ³ãƒ€ãƒ æ··åˆé¢æ¥ï¼ˆæœ€æ–°æ¨å¥¨ï¼‰
â”œâ”€â”€ model_provider.py           # å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«åˆ‡æ›¿ãƒ­ã‚¸ãƒƒã‚¯ç”¨ï¼ˆæœªä½¿ç”¨ï¼‰
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ .gitignore
â””â”€â”€ .python-version
```

---

## âš™ï¸ ç’°å¢ƒæº–å‚™

```bash
cd MultiAgent_Interview_Sim/agents_simulation
uv sync
```

ãƒ«ãƒ¼ãƒˆã«ã‚ã‚‹ `.env` ã§ Bedrock ãƒ¢ãƒ‡ãƒ«ãªã©ã‚’æŒ‡å®šã—ã¾ã™ï¼š

```bash
# .env
BEDROCK_MODEL_ID=bedrock.claude-3-sonnet
```

---

## ğŸš€ å®Ÿè¡Œæ–¹æ³•

```bash
# HRâ†’Applicantâ†’Dept ã®å›ºå®šãƒ•ãƒ­ãƒ¼
uv run python main_sync.py

# HRãƒ•ã‚§ãƒ¼ã‚ºâ†’Deptãƒ•ã‚§ãƒ¼ã‚ºã®è‡ªå¾‹é€²è¡Œ
uv run python main_autonomous.py

# âœ… HR/Dept ãŒãƒ©ãƒ³ãƒ€ãƒ ã«è³ªå•ã™ã‚‹æ··åˆé¢æ¥ï¼ˆMCPé€£æºï¼‰
uv run python main_mixed_random.py
```

å®Ÿè¡Œä¾‹ï¼š

```
=== é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆMCPé€£æºãƒ©ãƒ³ãƒ€ãƒ åˆ¶å¾¡ï¼‰é–‹å§‹ ===
[HR] ã‚ãªãŸã®PythonçµŒé¨“ã¨æ¥­å‹™ã§ã®æ´»ã‹ã—æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
[Applicant] ã¯ã„ã€ç§ã¯è£½é€ ç¾å ´ã®å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’Pythonã§è‡ªå‹•åˆ†æã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ...
[Dept] AWSã‚’ç”¨ã„ãŸå®Ÿè£…ã®å·¥å¤«ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
[Applicant] Lambdaã¨S3ã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒƒãƒè¨­è¨ˆã‚’è¡Œã„...
=== é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº† ===
```

---

## ğŸ§  å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè£…æ¦‚è¦ï¼ˆMCPé€£æºç‰ˆï¼‰

---

### â‘  å¿œå‹Ÿè€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ â€” `applicant_agent.py`

```python
import os
from dotenv import load_dotenv
from strands import Agent, tool
from agents.mcp_tool_client import call_mcp_tool

load_dotenv()
MODEL_ID = os.getenv("BEDROCK_MODEL_ID", "bedrock.claude-3-sonnet")

@tool
async def resume(section: str = "summary") -> str:
    """ğŸ“„ å±¥æ­´æ›¸æƒ…å ±ã‚’å–å¾—"""
    return await call_mcp_tool("resume", "resume", {"section": section})

@tool
async def applicant_profile(topic: str = "motivation") -> str:
    """ğŸ§­ å¿œå‹Ÿè€…ã®äººæ ¼ãƒ»å‹•æ©Ÿæƒ…å ±ã‚’å–å¾—"""
    return await call_mcp_tool("applicant_profile", "applicant_profile", {"topic": topic})

applicant_agent = Agent(
    name="ApplicantAgent",
    description="å¿œå‹Ÿè€…ã€‚è‡ªåˆ†ã®çµŒæ­´ã‚„ã‚¹ã‚­ãƒ«ã‚’èª¬æ˜ã™ã‚‹ã€‚",
    system_prompt=(
        "ã‚ãªãŸã¯é¢æ¥ã®å¿œå‹Ÿè€…ã§ã™ã€‚"
        "resumeï¼ˆè·å‹™çµŒæ­´ï¼‰ã¨ applicant_profileï¼ˆå‹•æ©Ÿãƒ»æ€è€ƒï¼‰ã‚’å‚ç…§ã—ã€"
        "å…·ä½“çš„ã‹ã¤èª å®Ÿã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    ),
    tools=[resume, applicant_profile],
    model=MODEL_ID,
)
```

---

### â‘¡ äººäº‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ â€” `hr_agent.py`

```python
import os
from dotenv import load_dotenv
from strands import Agent, tool
from agents.mcp_tool_client import call_mcp_tool

load_dotenv()
MODEL_ID = os.getenv("BEDROCK_MODEL_ID", "bedrock.claude-3-sonnet")

@tool
async def hr_questions(mode: str = "first", applicant_answer: str = "") -> str:
    """ğŸ’¬ äººäº‹è³ªå•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
    return await call_mcp_tool(
        "hr_questions",
        "hr_questions",
        {"mode": mode, "applicant_answer": applicant_answer},
    )

@tool
async def company_mission(section: str = "summary") -> str:
    """ğŸ¢ ä¼æ¥­ç†å¿µãƒ»ãƒ“ã‚¸ãƒ§ãƒ³ã‚’å–å¾—"""
    return await call_mcp_tool("company_mission", "company_mission", {"section": section})

hr_agent = Agent(
    name="HRAgent",
    description="äººäº‹æ‹…å½“ã€‚å¿œå‹Ÿè€…ã®äººç‰©åƒã‚„å¿—æœ›å‹•æ©Ÿãƒ»æˆæœã‚’æ·±æ˜ã‚Šã™ã‚‹ã€‚",
    system_prompt=(
        "ã‚ãªãŸã¯ä¼æ¥­ã®äººäº‹æ‹…å½“è€…ã§ã™ã€‚"
        "å¿œå‹Ÿè€…ã®æ€§æ ¼ãƒ»å¿—æœ›å‹•æ©Ÿãƒ»ã‚¹ã‚­ãƒ«ãƒ»æˆæœã‚’ç†è§£ã™ã‚‹ãŸã‚ã€"
        "company_mission ã¨ hr_questions ã‚’å‚ç…§ã—ãªãŒã‚‰è³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    ),
    tools=[company_mission, hr_questions],
    model=MODEL_ID,
)
```

---

### â‘¢ éƒ¨é–€è²¬ä»»è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ â€” `dept_agent.py`

```python
import os
from dotenv import load_dotenv
from strands import Agent, tool
from agents.mcp_tool_client import call_mcp_tool

load_dotenv()
MODEL_ID = os.getenv("BEDROCK_MODEL_ID", "bedrock.claude-3-sonnet")

@tool
async def dept_questions(context_summary: str = "") -> str:
    """ğŸ§‘â€ğŸ’» æŠ€è¡“é¢æ¥è³ªå•ã‚’å–å¾—"""
    return await call_mcp_tool(
        "dept_questions",
        "dept_questions",
        {"context_summary": context_summary},
    )

@tool
async def company_mission(section: str = "summary") -> str:
    """ğŸ¢ ä¼æ¥­ç†å¿µã‚’å–å¾—"""
    return await call_mcp_tool("company_mission", "company_mission", {"section": section})

dept_agent = Agent(
    name="DeptAgent",
    description="é–‹ç™ºéƒ¨é–€è²¬ä»»è€…ã€‚å®Ÿå‹™ã‚¹ã‚­ãƒ«ã‚„æŠ€è¡“çš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ã€‚",
    system_prompt=(
        "ã‚ãªãŸã¯é–‹ç™ºéƒ¨é–€ã®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚"
        "å¿œå‹Ÿè€…ã®æŠ€è¡“ã‚¹ã‚­ãƒ«ã‚„æ¥­å‹™é‚è¡Œèƒ½åŠ›ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€"
        "company_mission ã¨ dept_questions ã‚’æ´»ç”¨ã—ã¦è³ªå•ã—ã¦ãã ã•ã„ã€‚"
    ),
    tools=[company_mission, dept_questions],
    model=MODEL_ID,
)
```

---

### â‘£ MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå…±é€šé–¢æ•° â€” `mcp_tool_client.py`

```python
from typing import Any
from fastmcp import Client

MCP_BASE_URL = "http://127.0.0.1:8081/mcp"

async def call_mcp_tool(server: str, tool_name: str, params: dict) -> str:
    """
    âœ… FastMCPãƒ„ãƒ¼ãƒ«å…±é€šå‘¼ã³å‡ºã—é–¢æ•°ï¼ˆéåŒæœŸç‰ˆï¼‰
    - å®Ÿéš›ã®ãƒ„ãƒ¼ãƒ«åã¯ `<server>_<tool>` å½¢å¼ã€‚
    - FastMCPã®HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’éåŒæœŸã§åˆ©ç”¨ã€‚
    """
    try:
        async with Client(MCP_BASE_URL) as client:
            full_name = f"{server}_{tool_name}"
            result: Any = await client.call_tool(name=full_name, arguments=params)
            if isinstance(result, dict):
                return result.get("result", f"[{full_name}] ãƒ„ãƒ¼ãƒ«å¿œç­”ãªã—")
            return str(result)
    except Exception as e:
        return f"[MCPå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ @ {server}_{tool_name}] {e}"
```

---

### â‘¤ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â€” `util.py`

```python
from typing import Any

def extract_text(result: Any) -> str:
    """
    Strands AgentResult ã‹ã‚‰æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«æŠ½å‡ºã€‚
    å¤šæ§˜ãªæ§‹é€ ï¼ˆtext / response / message.content[0].text ç­‰ï¼‰ã«å¯¾å¿œã€‚
    """
    for attr in ("final_output", "output_text", "text", "response"):
        val = getattr(result, attr, None)
        if isinstance(val, str) and val.strip():
            return val

    try:
        msg = getattr(result, "message", None)
        content = getattr(msg, "content", None)
        if isinstance(content, list) and content:
            block = content[0]
            txt = block.get("text") if isinstance(block, dict) else getattr(block, "text", None)
            if isinstance(txt, str):
                return txt
        msg_text = getattr(msg, "text", None)
        if isinstance(msg_text, str):
            return msg_text
    except Exception:
        pass

    if isinstance(result, dict):
        for k in ("final_output", "output_text", "text", "response"):
            if isinstance(result.get(k), str):
                return result[k]

    return str(result)
```

---

### â‘¥ ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ â€” `main_mixed_random.py`ï¼ˆæœ€æ–°ç‰ˆï¼‰

```python
import os, asyncio, random
from dotenv import load_dotenv
from typing import Any, Dict, List
from agents.applicant_agent import applicant_agent
from agents.hr_agent import hr_agent
from agents.dept_agent import dept_agent
from agents.util import extract_text

load_dotenv()
print(f"[DEBUG] Loaded MODEL_ID = {os.getenv('BEDROCK_MODEL_ID')}")

Message = Dict[str, str]

def print_turn(role: str, text: str): print(f"[{role}] {text}\n")
def format_history(h: List[Message]) -> str: return "\n".join(f"{m['role']}: {m['content']}" for m in h)

def choose_interviewer(i: int) -> str:
    if i == 0: return "HR"
    p = 0.3 + min(i * 0.05, 0.4)
    return "Dept" if random.random() < p else "HR"

async def run_interview_mixed_random(max_rounds: int = 10):
    print("=== é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆMCPé€£æºãƒ©ãƒ³ãƒ€ãƒ åˆ¶å¾¡ï¼‰é–‹å§‹ ===\n")
    history: List[Message] = []

    for i in range(max_rounds):
        interviewer_role = choose_interviewer(i)
        agent = hr_agent if interviewer_role == "HR" else dept_agent

        interviewer_prompt = (
            "ä»¥ä¸‹ã¯ã“ã‚Œã¾ã§ã®é¢æ¥ãƒ­ã‚°ã§ã™ã€‚\n"
            f"{format_history(history)}\n\n"
            f"ã‚ãªãŸã¯{'äººäº‹æ‹…å½“ï¼ˆHRï¼‰' if interviewer_role=='HR' else 'é–‹ç™ºéƒ¨é–€è²¬ä»»è€…ï¼ˆDeptï¼‰'}ã§ã™ã€‚"
            "MCPãƒ„ãƒ¼ãƒ«ï¼ˆcompany_mission, dept_questions, hr_questionsï¼‰ã‚’åˆ©ç”¨ã—ã€"
            "æ¬¡ã®è³ªå•ã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚’1ã¤ã ã‘è¿”ã—ã¦ãã ã•ã„ã€‚\n"
            "é¢æ¥ã‚’çµ‚äº†ã—ã¦ã‚ˆã„å ´åˆã¯ <INTERVIEW_DONE> ã‚’æœ«å°¾ã«ä»˜ã‘ã¦ãã ã•ã„ã€‚"
        )

        interviewer_result = await agent.invoke_async(interviewer_prompt, model_kwargs={"temperature": 0.3})
        interviewer_text = extract_text(interviewer_result)
        done = "<INTERVIEW_DONE>" in interviewer_text
        interviewer_text = interviewer_text.replace("<INTERVIEW_DONE>", "").strip()

        history.append({"role": interviewer_role, "content": interviewer_text})
        print_turn(interviewer_role, interviewer_text)

        applicant_prompt = (
            "ä»¥ä¸‹ã¯ã“ã‚Œã¾ã§ã®é¢æ¥ãƒ­ã‚°ã§ã™ã€‚\n"
            f"{format_history(history)}\n\n"
            "ã‚ãªãŸã¯å¿œå‹Ÿè€…ã§ã™ã€‚resume ã¨ applicant_profile ã‚’å‚ç…§ã—ã€"
            "ç›´å‰ã®è³ªå•ã«è‡ªç„¶ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        )
        applicant_result = await applicant_agent.invoke_async(applicant_prompt, model_kwargs={"temperature": 0.3})
        applicant_text = extract_text(applicant_result)
        history.append({"role": "Applicant", "content": applicant_text})
        print_turn("Applicant", applicant_text)

        if done:
            print("=== é¢æ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†ï¼ˆ<INTERVIEW_DONE> æ¤œå‡ºï¼‰ ===")
            break

if __name__ == "__main__":
    asyncio.run(run_interview_mixed_random())
```

---

## âœ… ç‰¹å¾´ã¾ã¨ã‚

| æ©Ÿèƒ½                     | å†…å®¹                                                                           |
| ---------------------- | ---------------------------------------------------------------------------- |
| **MCPé€£æº**              | FastMCP ProxyçµŒç”±ã§ `resume` / `company_mission` / `hr_questions` ãªã©ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‘¼ã³å‡ºã— |
| **å®Œå…¨éåŒæœŸåŒ–**             | `await call_mcp_tool()` ã«çµ±ä¸€ã—ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹é…å»¶ã«ã‚‚å¼·ã„                                     |
| **Dify / Strands ä¸¡å¯¾å¿œ** | Difyã®MCPé€£æºã§ã‚‚å‹•ä½œç¢ºèªæ¸ˆã¿ï¼ˆ`http://localhost:8081/mcp/`ï¼‰                             |
| **Bedrockãƒ¢ãƒ‡ãƒ«å¯¾å¿œ**       | `.env` ã‹ã‚‰ `BEDROCK_MODEL_ID` ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å…±é€šè¨­å®š                              |
| **ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å¼·åŒ–**          | `extract_text()` ã«ã‚ˆã‚ŠStrandsçµæœã‚’æŸ”è»Ÿã«æŠ½å‡ºå¯èƒ½                                        |
| **é¢æ¥ãƒ©ãƒ³ãƒ€ãƒ åŒ–**            | HR / Dept ã®è³ªå•é †åºã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã—ã€ã‚ˆã‚Šè‡ªç„¶ãªé¢æ¥ã‚’å†ç¾                                            |

---

âœ… **æœ¬READMEã¯ã€éåŒæœŸMCPå¯¾å¿œç‰ˆï¼ˆ2025å¹´11æœˆãƒªãƒ“ã‚¸ãƒ§ãƒ³ï¼‰** ã«å®Œå…¨æº–æ‹ ã—ã¦ã„ã¾ã™ã€‚
